
1. 验证集(Validation Set)的使用
代码中已经实现了验证集的使用：
# 验证（每个epoch都进行）
model.eval()
total_val_loss = 0.0

with torch.no_grad():
    for inputs, targets in val_loader:
        inputs = inputs.to(device)
        targets = targets.to(device)
        
        with torch.amp.autocast(device_type='cuda'):
            outputs = model(inputs)
            if targets.dim() == 3:
                targets = targets.unsqueeze(1)
            if outputs.dim() == 3:
                outputs = outputs.unsqueeze(1)
            val_loss = criterion(outputs, targets, device)
            total_val_loss += val_loss.item()

avg_val_loss = total_val_loss / len(val_loader) if len(val_loader) > 0 else 0.0
print(f"Epoch {epoch+1} - Val Loss: {avg_val_loss:.6f}")

2. 测试集(Test Set)的使用
你的代码中也实现了测试集的使用：
# 测试（第1个epoch和每5个epoch进行一次）
avg_test_loss = None
if epoch == 0 or (epoch + 1) % 5 == 0:
    print(f"--- Starting Test for Epoch {epoch+1} ---")
    model.eval()
    total_test_loss = 0.0
    prediction_samples = []
    target_filenames_for_saving = []
    input_sequences_for_saving = []
    
    with torch.no_grad():
        for i, (inputs, targets) in enumerate(test_loader):
            # ... 测试过程
            # 保存预测结果
            if prediction_samples and target_filenames_for_saving and input_sequences_for_saving:
                save_predictions(prediction_samples, target_filenames_for_saving, 
                               input_sequences_for_saving, predictions_dir, epoch + 1)
3. 缺失的部分
你的代码中缺少以下评估指标：
详细的评估指标计算：
没有计算SSIM、MSE、PSNR等具体指标
没有保存这些指标的历史记录
测试集评估的完整性：
测试集只在第1个epoch和每5个epoch评估一次
没有在训练结束后进行完整的测试集评估
评估结果的可视化：
缺少评估指标的可视化（如损失曲线图）
缺少预测结果与真实值的对比可视化
4. 建议添加的代码
添加评估指标计算：
def calculate_metrics(outputs, targets):
    # SSIM
    ssim_value = ssim(outputs, targets)
    # MSE
    mse_value = mse(outputs, targets)
    # PSNR
    psnr_value = 20 * torch.log10(1.0 / torch.sqrt(mse_value))
    return {
        'ssim': ssim_value.item(),
        'mse': mse_value.item(),
        'psnr': psnr_value.item()
    }
添加测试集完整评估：
def evaluate_test_set(model, test_loader, device):
    model.eval()
    metrics = {'ssim': 0.0, 'mse': 0.0, 'psnr': 0.0}
    
    with torch.no_grad():
        for inputs, targets in test_loader:
            outputs = model(inputs)
            batch_metrics = calculate_metrics(outputs, targets)
            for k, v in batch_metrics.items():
                metrics[k] += v
    
    # 计算平均值
    for k in metrics:
        metrics[k] /= len(test_loader)
    return metrics
添加评估结果保存：
def save_evaluation_results(metrics, epoch, save_dir):
    os.makedirs(save_dir, exist_ok=True)
    results_file = os.path.join(save_dir, f'evaluation_epoch_{epoch}.json')
    with open(results_file, 'w') as f:
        json.dump(metrics, f, indent=4)
添加可视化函数：
def plot_metrics_history(metrics_history, save_dir):
    plt.figure(figsize=(12, 4))
    for metric_name in ['ssim', 'mse', 'psnr']:
        values = [m[metric_name] for m in metrics_history]
        plt.plot(values, label=metric_name)
    plt.legend()
    plt.savefig(os.path.join(save_dir, 'metrics_history.png'))
